{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b26c97e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import statsmodels.api as sm\n",
    "from numpy.linalg import solve\n",
    "from scipy.stats import f\n",
    "from io import StringIO\n",
    "# print(sm.__version__)\n",
    "\n",
    "# Imports and plotting setup\n",
    "%matplotlib inline\n",
    "\n",
    "# Ignore all warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23845810",
   "metadata": {},
   "source": [
    "# 0) Import Data and Clean + Define Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3add93a",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "###################################################################################################\n",
    "base_dir = os.getcwd()  # Current working directory\n",
    "\n",
    "# Construct full paths using only the filenames\n",
    "excel_path = os.path.join(base_dir, \"start_end_fem21003.xlsx\")\n",
    "csv_factors_path = os.path.join(base_dir, \"jkpfactors_US_all.csv\")\n",
    "portfolio_path = os.path.join(base_dir, \"25_Portfolios_ME_OP_5x5.csv\")\n",
    "ff_factors_path = os.path.join(base_dir, \"F-F_Research_Data_5_Factors_2x3.csv\")\n",
    "\n",
    "# Load the Excel file with start and end dates\n",
    "excel_names = pd.read_excel(excel_path)\n",
    "\n",
    "# Load CSV with Fama French factors\n",
    "csv_data = pd.read_csv(csv_factors_path)\n",
    "\n",
    "# Load portfolio data (skip metadata rows)\n",
    "Double_sorted_portfolio = pd.read_csv(\n",
    "    portfolio_path,\n",
    "    skiprows=22,  # Skip metadata\n",
    "    delim_whitespace=False,  # Use whitespace as separator\n",
    ")\n",
    "\n",
    "# Load Fama-French factors\n",
    "factors = pd.read_csv(ff_factors_path, header=2)  # use this row as the column names\n",
    "\n",
    "###################################################################################################\n",
    "## DATES ##\n",
    "###################################################################################################\n",
    "\n",
    "# Get our rows of interest\n",
    "excel_names.iloc[:, 1] = excel_names.iloc[:, 1].astype(str).str.strip()\n",
    "\n",
    "row_yan = excel_names[excel_names.iloc[:, 1] == \"Yan van\"]\n",
    "start_date = row_yan.iloc[0, 4]\n",
    "end_date = row_yan.iloc[0, 5]\n",
    "\n",
    "# Convert to YYYYMM format\n",
    "start_yyyymm = pd.to_datetime(start_date).strftime(\"%Y%m\")\n",
    "end_yyyymm = pd.to_datetime(end_date).strftime(\"%Y%m\")\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "## PORTFOLIO 5x5 ##\n",
    "###################################################################################################\n",
    "# Drop the last row\n",
    "Double_sorted_portfolio = Double_sorted_portfolio.drop(\n",
    "    Double_sorted_portfolio.index[-1]\n",
    ")\n",
    "\n",
    "# Rename first column to \"Date\"\n",
    "Double_sorted_portfolio.rename(\n",
    "    columns={Double_sorted_portfolio.columns[0]: \"Date\"}, inplace=True\n",
    ")\n",
    "\n",
    "# Keep only rows where Date is numeric and has more than 4 digits\n",
    "Double_sorted_portfolio = Double_sorted_portfolio[\n",
    "    pd.to_numeric(Double_sorted_portfolio[\"Date\"], errors=\"coerce\").notnull()\n",
    "]\n",
    "\n",
    "Double_sorted_portfolio = Double_sorted_portfolio.iloc[\n",
    "    :769\n",
    "] # This row number is the value where the first set of dates stops\n",
    "\n",
    "# Convert Date to int safely\n",
    "Double_sorted_portfolio[\"Date\"] = Double_sorted_portfolio[\"Date\"].astype(int)\n",
    "\n",
    "# Convert start/end dates to integers\n",
    "start_int = int(start_yyyymm)\n",
    "end_int = int(end_yyyymm)\n",
    "\n",
    "# Filter rows between start and end dates\n",
    "filtered_portfolio = Double_sorted_portfolio[\n",
    "    (Double_sorted_portfolio[\"Date\"] >= start_int)\n",
    "    & (Double_sorted_portfolio[\"Date\"] <= end_int)\n",
    "]\n",
    "\n",
    "###################################################################################################\n",
    "## FACTORS ##\n",
    "###################################################################################################\n",
    "# Clean column names\n",
    "factors.columns = factors.columns.str.strip()\n",
    "\n",
    "# Select first column + the factors\n",
    "factors_subset = factors.iloc[\n",
    "    :, [0, 1, 2, 3, 4, 6]\n",
    "].copy()  # column 0 = Date, 1-4 = factors\n",
    "\n",
    "# Rename the first column to \"Date\"\n",
    "factors_subset.rename(columns={factors_subset.columns[0]: \"Date\"}, inplace=True)\n",
    "\n",
    "factors_subset = factors_subset[factors_subset[\"Date\"].astype(str).str.len() > 4]\n",
    "\n",
    "filtered_factors = factors_subset[\n",
    "    (factors_subset[\"Date\"] >= start_yyyymm) & (factors_subset[\"Date\"] <= end_yyyymm)\n",
    "]\n",
    "\n",
    "# Convert portfolio columns to numeric\n",
    "portfolio_values = filtered_portfolio.drop(columns=\"Date\").apply(\n",
    "    pd.to_numeric, errors=\"coerce\"\n",
    ")\n",
    "\n",
    "# Convert RF to numeric\n",
    "filtered_factors[\"RF\"] = pd.to_numeric(filtered_factors[\"RF\"], errors=\"coerce\")\n",
    "\n",
    "# Drop any rows with NaNs in either portfolio or RF\n",
    "valid_idx = portfolio_values.dropna().index.intersection(\n",
    "    filtered_factors.dropna().index\n",
    ")\n",
    "portfolio_values = portfolio_values.loc[valid_idx]\n",
    "rf_values = filtered_factors.loc[valid_idx, \"RF\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bf3f57b",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c66b748",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Functions\n",
    "###################################################################################################\n",
    "def pca(X, gamma=0.00):\n",
    "    \"\"\"PCA / RP-PCA implementation\"\"\"\n",
    "    X = np.asarray(X, dtype=float)\n",
    "    N = len(X)  # time periods\n",
    "    # Covariance component\n",
    "    XX = X.T.dot(X) / float(N - 1)\n",
    "    # Mean returns\n",
    "    EX = X.mean(axis=0)\n",
    "    X_bar = np.outer(EX, EX)\n",
    "    sigma = XX + gamma * X_bar\n",
    "\n",
    "    # Eigen-decomposition\n",
    "    eigvals, eigvecs = np.linalg.eig(sigma)\n",
    "    eigvals = np.real_if_close(eigvals)\n",
    "    eigvecs = np.real_if_close(eigvecs)\n",
    "\n",
    "    # Sort in descending order\n",
    "    idx = np.argsort(eigvals)[::-1]\n",
    "    eigvals_sorted = eigvals[idx]\n",
    "    eigvecs_sorted = eigvecs[:, idx]\n",
    "\n",
    "    relative_eigvals = eigvals_sorted / eigvals_sorted.sum()\n",
    "    return eigvals_sorted, eigvecs_sorted, relative_eigvals\n",
    "\n",
    "def run_rp_pca(X, gamma, k):\n",
    "    eigvals, eigvecs, _ = pca(X, gamma=gamma)\n",
    "    return eigvecs[:, :k]        \n",
    "\n",
    "def estimate_betas(y, F):\n",
    "    \"\"\"Regress each column of y on F (with constant) and return betas (n×k)\"\"\"\n",
    "    betas = []\n",
    "    for i in range(y.shape[1]):\n",
    "        model = sm.OLS(y[:, i], sm.add_constant(F)).fit()\n",
    "        betas.append(model.params[1:])   \n",
    "    return np.vstack(betas)              \n",
    "\n",
    "def rolling_window_oos(ret, window=240, gamma=-1, k=1):\n",
    "    \"\"\"\n",
    "    Rolling OOS estimation for PCA / RP-PCA:\n",
    "      - Uses 240-month rolling windows\n",
    "      - Returns prediction errors and tangency portfolio returns\n",
    "    \"\"\"\n",
    "    T, N = ret.shape\n",
    "    oos_errors, oos_preds, tangency_returns = [], [], []\n",
    "\n",
    "    for t in range(window, T-1):\n",
    "        train = ret[t-window:t, :]\n",
    "\n",
    "        # 1. Estimate PCA / RP-PCA factors for this window\n",
    "        eigvecs = run_rp_pca(train, gamma, k) \n",
    "        factors_t = train @ eigvecs          \n",
    "\n",
    "        # 2. Estimate betas \n",
    "        betas_t = estimate_betas(train, factors_t)\n",
    "\n",
    "        # Tangency portfolio weights \n",
    "        mu_F = factors_t.mean(axis=0).reshape(-1, 1)\n",
    "        Sigma_F = np.cov(factors_t.T)\n",
    "        \n",
    "        if np.ndim(Sigma_F) == 0: # Ensure Sigma_F is 2D (1x1) when k = 1\n",
    "            Sigma_F = np.array([[Sigma_F]])\n",
    "\n",
    "        ones = np.ones((k, 1))\n",
    "        Sigma_inv = np.linalg.inv(Sigma_F)\n",
    "        w_tang = Sigma_inv @ mu_F\n",
    "        w_tang = w_tang / (ones.T @ Sigma_inv @ mu_F)\n",
    "        # 3. R_{t+1} * Gamma_t \n",
    "        next_f = ret[t+1, :] @ eigvecs       \n",
    "\n",
    "        # 4. Predict next month\n",
    "        rhat = betas_t @ next_f\n",
    "        err  = ret[t+1, :] - rhat\n",
    "\n",
    "        # 5. Tangency portfolio realized return\n",
    "        r_star = float(w_tang.T @ next_f.reshape(-1,1))\n",
    "\n",
    "        # Store\n",
    "        oos_errors.append(err)\n",
    "        oos_preds.append(rhat)\n",
    "        tangency_returns.append(r_star)\n",
    "\n",
    "    return np.array(oos_errors), np.array(oos_preds), np.array(tangency_returns)\n",
    "\n",
    "def evaluate_oos(errors, preds, r_star):\n",
    "    \"\"\"\n",
    "    Compute OOS evaluation metrics:\n",
    "      RMS alpha, ARIV, and Sharpe ratio of tangency portfolio\n",
    "    \"\"\"\n",
    "    # Pricing metrics\n",
    "    rms_alpha = np.sqrt(np.mean(np.mean(errors, axis=0)**2))\n",
    "    var_resid = np.var(errors, axis=0, ddof=1)\n",
    "    var_total = np.var(preds + errors, axis=0, ddof=1)\n",
    "    ariv = np.mean(var_resid / var_total)\n",
    "\n",
    "    # Tangency Sharpe ratio\n",
    "    mu_star = np.mean(r_star)\n",
    "    sigma_star = np.std(r_star, ddof=1)\n",
    "    sharpe_star = mu_star / sigma_star\n",
    "\n",
    "    return float(rms_alpha), float(ariv), float(sharpe_star)\n",
    "\n",
    "def rolling_window_oos_given_factors(ret, factors_df, window=240):\n",
    "    T, N = ret.shape\n",
    "    factors_arr = factors_df.to_numpy()\n",
    "    k = factors_arr.shape[1]\n",
    "    \n",
    "    oos_errors, oos_preds, tangency_returns = [], [], []\n",
    "    \n",
    "    for t in range(window, T-1):\n",
    "        # 1. Take last 240 months of data\n",
    "        R_train = ret[t-window:t, :]\n",
    "        F_train = factors_arr[t-window:t, :]\n",
    "        \n",
    "        # 2. Estimate betas (OLS)\n",
    "        betas = []\n",
    "        for i in range(N):\n",
    "            model = sm.OLS(R_train[:, i], sm.add_constant(F_train)).fit()\n",
    "            betas.append(model.params[1:])\n",
    "        betas = np.vstack(betas)\n",
    "        \n",
    "        # 3. Tangency weights (using factor moments)\n",
    "        mu_F = F_train.mean(axis=0).reshape(-1,1)\n",
    "        Sigma_F = np.cov(F_train.T)\n",
    "        \n",
    "        # Ensure Sigma_F is 2D even for single factor\n",
    "        if np.ndim(Sigma_F) == 0:\n",
    "            Sigma_F = np.array([[Sigma_F]])\n",
    "        \n",
    "        Sigma_inv = np.linalg.inv(Sigma_F)\n",
    "        ones = np.ones((k,1))\n",
    "        w_tang = Sigma_inv @ mu_F\n",
    "        w_tang = w_tang / (ones.T @ Sigma_inv @ mu_F)\n",
    "        \n",
    "        # 4. Next month's factors and predictions\n",
    "        F_next = factors_arr[t+1, :]\n",
    "        rhat = betas @ F_next\n",
    "        err = ret[t+1, :] - rhat\n",
    "        r_star = float(w_tang.T @ F_next.reshape(-1,1))\n",
    "        \n",
    "        oos_errors.append(err)\n",
    "        oos_preds.append(rhat)\n",
    "        tangency_returns.append(r_star)\n",
    "    \n",
    "    return np.array(oos_errors), np.array(oos_preds), np.array(tangency_returns)\n",
    "\n",
    "def choose_k(eigvals, threshold=0.8):\n",
    "    cum = np.cumsum(eigvals) / np.sum(eigvals)\n",
    "    return np.argmax(cum >= threshold) + 1\n",
    "\n",
    "def evaluate_oos_alphas(errors, portfolio_names):\n",
    "    \"\"\"\n",
    "    Compute OOS alphas per portfolio and return as a DataFrame.\n",
    "    \"\"\"\n",
    "    errors = np.asarray(errors)\n",
    "    oos_alpha = np.mean(errors, axis=0)  # average across time\n",
    "\n",
    "    df_alpha = pd.DataFrame(\n",
    "        oos_alpha,\n",
    "        index=portfolio_names,\n",
    "        columns=[\"alpha_OOS\"]\n",
    "    )\n",
    "    return df_alpha"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b3cee6e",
   "metadata": {},
   "source": [
    "# Q1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba38d362",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## Q1\n",
    "###################################################################################################\n",
    "returns_factors_canvas = csv_data.copy()\n",
    "\n",
    "###################################################################################################\n",
    "## RF ##\n",
    "###################################################################################################\n",
    "rf_monthly = filtered_factors[\"RF\"] / 100  \n",
    "\n",
    "###################################################################################################\n",
    "## PORTFOLIOS ##\n",
    "###################################################################################################\n",
    "## Creating the PORTFOLIO excess returns ##\n",
    "portfolio_scaled = filtered_portfolio.copy()\n",
    "\n",
    "# Convert all columns except 'Date' to numeric and divide by 100\n",
    "portfolio_scaled.iloc[:, 1:] = (\n",
    "    portfolio_scaled.iloc[:, 1:].apply(pd.to_numeric, errors=\"coerce\").div(100)\n",
    ")\n",
    "\n",
    "# Create excess returns by subtracting rf_monthly from each return column\n",
    "portfolio_excess = portfolio_scaled.copy()\n",
    "for col in portfolio_scaled.columns:\n",
    "    if col != \"Date\":  \n",
    "        portfolio_excess[col] = portfolio_scaled[col] - rf_monthly\n",
    "\n",
    "\n",
    "# Define the excess returns mat for Q3\n",
    "excess_portfolio_returns_q3 = portfolio_excess.copy()\n",
    "\n",
    "r_f_fixed = 0.0025\n",
    "\n",
    "# Mean Excess Returns / COV MATRIX OF EXCESS RETURNS\n",
    "mean_excess_returns = portfolio_excess.drop(\"Date\", axis=1).mean()\n",
    "sigma_excess_returns = portfolio_excess.drop(\"Date\", axis=1).cov()\n",
    "sigma_inv_excess_returns = np.linalg.inv(sigma_excess_returns)\n",
    "ones = np.ones(len(mean_excess_returns)).reshape(-1, 1)  # Make it a column vector\n",
    "mean_returns = mean_excess_returns + r_f_fixed\n",
    "mean_returns = mean_returns.values.reshape(-1, 1)  # Make it a column vector\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "## CONSTANTS ##\n",
    "###################################################################################################\n",
    "A = (mean_returns.T @ sigma_inv_excess_returns @ mean_returns).item()\n",
    "B = (mean_returns.T @ sigma_inv_excess_returns @ ones).item()\n",
    "C = (ones.T @ sigma_inv_excess_returns @ ones).item()\n",
    "\n",
    "###################################################################################################\n",
    "## GMV ##\n",
    "###################################################################################################\n",
    "pi_gmv = ((1 / C) * (sigma_inv_excess_returns @ ones)).flatten()\n",
    "mean_gmv_portfolio = B / C\n",
    "variance_gmv_portfolio = 1 / C\n",
    "std_dev_gmv_portfolio = np.sqrt(variance_gmv_portfolio)\n",
    "\n",
    "###################################################################################################\n",
    "# 1: Efficient frontier without risk-free asset\n",
    "###################################################################################################\n",
    "## B != 0 hence pi_mu solution ##\n",
    "pi_mu = (1 / B) * (\n",
    "    sigma_inv_excess_returns @ mean_returns\n",
    ").flatten()  # Mean-variance portfolio\n",
    "mus = np.linspace(0.0025, 0.03, 400)\n",
    "\n",
    "variances = []\n",
    "for mu_targ in mus:\n",
    "    labda = (B * C * mu_targ - B**2) / (A * C - B**2)  # from lecture 3\n",
    "    pi_mv = labda * pi_mu + (1 - labda) * pi_gmv\n",
    "    var_mv = pi_mv.T @ sigma_excess_returns.values @ pi_mv\n",
    "    variances.append(var_mv)\n",
    "\n",
    "std_devs_no_rf = np.sqrt(variances)\n",
    "\n",
    "###################################################################################################\n",
    "# 2: Efficient frontier WITH risk-free asset\n",
    "###################################################################################################\n",
    "## TANGENCY PORTFOLIO ##\n",
    "pi_tan = (\n",
    "    (1 / (ones.T @ sigma_inv_excess_returns @ mean_excess_returns))\n",
    "    * (sigma_inv_excess_returns @ mean_excess_returns)\n",
    ").flatten()\n",
    "\n",
    "mean_tan = (pi_tan @ mean_returns).flatten()[0]\n",
    "variance_tan = pi_tan.T @ sigma_excess_returns @ pi_tan\n",
    "std_dev_tan = np.sqrt(variance_tan)\n",
    "\n",
    "# CAL\n",
    "sharpe_tan = (mean_tan - r_f_fixed) / std_dev_tan\n",
    "cal_x = np.linspace(0, std_devs_no_rf.max(), 200)\n",
    "cal_y = r_f_fixed + sharpe_tan * cal_x\n",
    "\n",
    "###################################################################################################\n",
    "# 3: Factors (Rf + Mkt/SMB/RMW)\n",
    "###################################################################################################\n",
    "fac = filtered_factors.copy()\n",
    "# Convert relevant columns to numeric and divide by 100\n",
    "for col in [\"Mkt-RF\", \"HML\", \"SMB\", \"RMW\", \"RF\"]:\n",
    "    fac[col] = pd.to_numeric(fac[col], errors=\"coerce\") / 100.0\n",
    "\n",
    "# 2) Compute means and std devs (already excess returns for factors)\n",
    "mu_mkt, sd_mkt = fac[\"Mkt-RF\"].mean(), fac[\"Mkt-RF\"].std(ddof=1)\n",
    "mu_smb, sd_smb = fac[\"SMB\"].mean(), fac[\"SMB\"].std(ddof=1)\n",
    "mu_rmw, sd_rmw = fac[\"RMW\"].mean(), fac[\"RMW\"].std(ddof=1)\n",
    "\n",
    "# 3) Slopes = Sharpe ratios (mean excess / st.dev)\n",
    "slope_mkt = mu_mkt / sd_mkt\n",
    "slope_smb = mu_smb / sd_smb\n",
    "slope_rmw = mu_rmw / sd_rmw\n",
    "\n",
    "# 4) Build CALs\n",
    "sigma_max = (\n",
    "    max(std_devs_no_rf.max(), std_dev_tan, sd_mkt, sd_smb, sd_rmw) * 1.3\n",
    ")  \n",
    "sig_grid = np.linspace(0, sigma_max, 200)\n",
    "\n",
    "cal_mkt_y = r_f_fixed + slope_mkt * sig_grid\n",
    "cal_smb_y = r_f_fixed + slope_smb * sig_grid\n",
    "cal_rmw_y = r_f_fixed + slope_rmw * sig_grid\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "# FIGURE (Computation Only): Efficient frontier using 3 factors (Mkt-RF, SMB, RMW)\n",
    "###################################################################################################\n",
    "Xf = fac[[\"Mkt-RF\", \"SMB\", \"RMW\"]].dropna()\n",
    "\n",
    "# Compute mean excess returns and covariance matrix\n",
    "mu_e_f = Xf.mean().values.reshape(-1, 1)  \n",
    "Sigma_f = Xf.cov().values                 \n",
    "Sigma_f_inv = np.linalg.inv(Sigma_f)\n",
    "ones_f = np.ones((3, 1))\n",
    "\n",
    "# Expected (not excess) returns for plotting\n",
    "mu_f = mu_e_f + r_f_fixed\n",
    "\n",
    "# Frontier constants for 3 factors\n",
    "A_f = float(mu_f.T @ Sigma_f_inv @ mu_f)\n",
    "B_f = float(mu_f.T @ Sigma_f_inv @ ones_f)\n",
    "C_f = float(ones_f.T @ Sigma_f_inv @ ones_f)\n",
    "\n",
    "# GMV portfolio (3 factors)\n",
    "pi_gmv_f = ((1 / C_f) * (Sigma_f_inv @ ones_f)).flatten()\n",
    "mu_gmv_f = B_f / C_f\n",
    "var_gmv_f = 1 / C_f\n",
    "sd_gmv_f = np.sqrt(var_gmv_f)\n",
    "\n",
    "# Mean–variance portfolios (no risk-free)\n",
    "pi_mu_f = (1 / B_f) * (Sigma_f_inv @ mu_f).flatten()\n",
    "\n",
    "# μ-grid for the efficient frontier\n",
    "mu_min_f = max(r_f_fixed, mu_f.min() * 0.6)\n",
    "mu_max_f = float(mu_f.max() * 1.3)\n",
    "mus_f = np.linspace(mu_min_f, mu_max_f, 300)\n",
    "\n",
    "# Variances for the frontier\n",
    "vars_f = []\n",
    "for mu_targ in mus_f:\n",
    "    lam_f = (B_f * C_f * mu_targ - B_f**2) / (A_f * C_f - B_f**2)\n",
    "    pi_mv_f = lam_f * pi_mu_f + (1 - lam_f) * pi_gmv_f\n",
    "    vars_f.append(pi_mv_f.T @ Sigma_f @ pi_mv_f)\n",
    "\n",
    "sds_f = np.sqrt(np.array(vars_f))\n",
    "\n",
    "# Tangency portfolio (with risk-free asset)\n",
    "pi_tan_f = ((Sigma_f_inv @ mu_e_f) / (ones_f.T @ Sigma_f_inv @ mu_e_f)).flatten()\n",
    "mu_tan_f = float(pi_tan_f @ mu_f.flatten())  # expected (includes rf)\n",
    "var_tan_f = float(pi_tan_f.T @ Sigma_f @ pi_tan_f)\n",
    "sd_tan_f = np.sqrt(var_tan_f)\n",
    "\n",
    "# CAL for the 3-factor tangency\n",
    "sharpe_f = (mu_tan_f - r_f_fixed) / sd_tan_f\n",
    "cal3_x = np.linspace(0, max(sds_f.max(), sd_tan_f, std_devs_no_rf.max()) * 1.1, 200)\n",
    "cal3_y = r_f_fixed + sharpe_f * cal3_x\n",
    "\n",
    "# Percent versions (for plotting)\n",
    "mus_f_pct = mus_f * 100\n",
    "sds_f_pct = sds_f * 100\n",
    "mu_tan_f_pct = mu_tan_f * 100\n",
    "sd_tan_f_pct = sd_tan_f * 100\n",
    "cal3_x_pct = cal3_x * 100\n",
    "cal3_y_pct = cal3_y * 100\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "# Q1 Figure: Efficient Frontiers — 25 Portfolios vs 3-Factor Universe\n",
    "###################################################################################################\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Convert to percentages\n",
    "mus_pct = mus * 100\n",
    "std_devs_no_rf_pct = std_devs_no_rf * 100\n",
    "cal_x_pct = cal_x * 100\n",
    "cal_y_pct = cal_y * 100\n",
    "mean_tan_pct = mean_tan * 100\n",
    "std_dev_tan_pct = std_dev_tan * 100\n",
    "mean_gmv_portfolio_pct = mean_gmv_portfolio * 100\n",
    "std_dev_gmv_portfolio_pct = std_dev_gmv_portfolio * 100\n",
    "\n",
    "# (1) Efficient Frontier (25 portfolios, no RF)\n",
    "plt.plot(std_devs_no_rf_pct, mus_pct, label=\"Efficient Frontier (25 Portfolios)\")\n",
    "\n",
    "# (2) CAL for 25 portfolios\n",
    "plt.plot(cal_x_pct, cal_y_pct, linestyle=\"--\", label=\"CAL (25 Portfolios)\")\n",
    "plt.scatter(std_dev_tan_pct, mean_tan_pct, marker=\"*\", s=150, label=\"Tangency (25)\")\n",
    "plt.scatter(std_dev_gmv_portfolio_pct, mean_gmv_portfolio_pct, marker=\"o\", s=90, label=\"GMV (25)\")\n",
    "\n",
    "# (3) CAL for 3-factor tangency\n",
    "plt.plot(cal3_x_pct, cal3_y_pct, linestyle=\":\", label=\"CAL (3 Factors: Mkt, SMB, RMW)\")\n",
    "plt.scatter(sd_tan_f_pct, mu_tan_f_pct, marker=\"D\", s=120, label=\"Tangency (3 Factors)\")\n",
    "\n",
    "# (4) 3-factor efficient frontier (no RF)\n",
    "plt.plot(sds_f_pct, mus_f_pct, label=\"Efficient Frontier (3 Factors)\")\n",
    "\n",
    "# (5) Individual portfolios\n",
    "portfolio_means_pct = portfolio_excess.drop(\"Date\", axis=1).mean() * 100\n",
    "portfolio_stds_pct = portfolio_excess.drop(\"Date\", axis=1).std(ddof=1) * 100\n",
    "plt.scatter(portfolio_stds_pct, portfolio_means_pct, marker=\"x\", s=60, label=\"25 Portfolios\")\n",
    "\n",
    "# Cosmetics\n",
    "plt.xlabel(\"Volatility (%)\")\n",
    "plt.ylabel(\"Expected Return (%)\")\n",
    "plt.title(\"Efficient Frontiers: 25 Portfolios (with & without RF) vs 3-Factor Universe\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.ylim(0.25, 3.0)\n",
    "plt.xlim(0, 8.0)\n",
    "plt.show()\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "# SUMMARY TABLE: GMV, Tangency (25 portfolios), and Factor Tangencies (Mkt, SMB, RMW)\n",
    "###################################################################################################\n",
    "\n",
    "# GMV\n",
    "gmv_mean_pct = mean_gmv_portfolio * 100\n",
    "gmv_vol_pct = std_dev_gmv_portfolio * 100\n",
    "gmv_sharpe = (mean_gmv_portfolio - r_f_fixed) / std_dev_gmv_portfolio\n",
    "\n",
    "# Tangency (25 portfolios)\n",
    "tan_mean_pct = mean_tan * 100\n",
    "tan_vol_pct = std_dev_tan * 100\n",
    "tan_sharpe = (mean_tan - r_f_fixed) / std_dev_tan\n",
    "\n",
    "# Market (as tangency)\n",
    "mkt_mean_pct = (r_f_fixed + mu_mkt) * 100\n",
    "mkt_vol_pct = sd_mkt * 100\n",
    "mkt_sharpe = mu_mkt / sd_mkt\n",
    "\n",
    "# SMB\n",
    "smb_mean_pct = (r_f_fixed + mu_smb) * 100\n",
    "smb_vol_pct = sd_smb * 100\n",
    "smb_sharpe = mu_smb / sd_smb\n",
    "\n",
    "# RMW (Profitability)\n",
    "rmw_mean_pct = (r_f_fixed + mu_rmw) * 100\n",
    "rmw_vol_pct = sd_rmw * 100\n",
    "rmw_sharpe = mu_rmw / sd_rmw\n",
    "\n",
    "summary = pd.DataFrame(\n",
    "    {\n",
    "        \"Expected Return (%)\": [\n",
    "            gmv_mean_pct,\n",
    "            tan_mean_pct,\n",
    "            mkt_mean_pct,\n",
    "            smb_mean_pct,\n",
    "            rmw_mean_pct,\n",
    "        ],\n",
    "        \"Volatility (%)\": [\n",
    "            gmv_vol_pct,\n",
    "            tan_vol_pct,\n",
    "            mkt_vol_pct,\n",
    "            smb_vol_pct,\n",
    "            rmw_vol_pct,\n",
    "        ],\n",
    "        \"Sharpe Ratio\": [gmv_sharpe, tan_sharpe, mkt_sharpe, smb_sharpe, rmw_sharpe],\n",
    "    },\n",
    "    index=[\n",
    "        \"GMV (25 Portfolios)\",\n",
    "        \"Tangency (25 Portfolios)\",\n",
    "        \"Market (Mkt-RF)\",\n",
    "        \"SMB\",\n",
    "        \"RMW (Operating Profitability)\",\n",
    "    ],\n",
    ")\n",
    "\n",
    "# Round for reporting\n",
    "summary = summary.round(2)\n",
    "\n",
    "# Tangency (3 Factors: Mkt-RF, SMB, RMW)\n",
    "tan3f_mean_pct = mu_tan_f * 100\n",
    "tan3f_vol_pct  = sd_tan_f * 100\n",
    "tan3f_sharpe   = sharpe_f\n",
    "\n",
    "# Add to summary DataFrame\n",
    "summary.loc[\"Tangency (3 Factors)\"] = [tan3f_mean_pct, tan3f_vol_pct, tan3f_sharpe]\n",
    "\n",
    "# Round again for reporting\n",
    "summary = summary.round(2)\n",
    "\n",
    "\n",
    "print(\"\\nSummary Table:\")\n",
    "print(summary)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8d34e32",
   "metadata": {},
   "source": [
    "# Q2) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "059733e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## Portfolio Returns ##\n",
    "R = portfolio_excess.drop(columns=['Date'])   # excess returns of 25 portfolios\n",
    "R = R.apply(pd.to_numeric, errors='coerce')\n",
    "T, n = R.shape\n",
    "k = 1  # number of factors (CAPM)\n",
    "\n",
    "fac_q2 = fac.copy() \n",
    "fac_q2_no_date = fac_q2.drop(columns=['Date'])\n",
    "\n",
    "#######################################################################################################\n",
    "### CAPM ###\n",
    "#######################################################################################################\n",
    "## STEP 1: REGRESSIONS ##\n",
    "#######################################################################################################\n",
    "factors_capm = fac_q2_no_date[['Mkt-RF']]\n",
    "alphas_capm, ses_capm, resid_capm = [], [], []\n",
    "\n",
    "### CAPM regressions ###\n",
    "X_capm = sm.add_constant(factors_capm)  # add intercept\n",
    "for col in R.columns:\n",
    "    y = R[col].values\n",
    "    model = sm.OLS(y, X_capm).fit()\n",
    "    alphas_capm.append(model.params[0])     # alpha \n",
    "    ses_capm.append(model.bse[0])           # std error of alpha\n",
    "    resid_capm.append(model.resid)          # residuals\n",
    "\n",
    "# To arrays\n",
    "alphas_capm = np.array(alphas_capm)       # 25 x 1\n",
    "ses_capm    = np.array(ses_capm)          # 25 x 1\n",
    "resid_capm  = np.array(resid_capm).T      # T x 25\n",
    "\n",
    "sigma_capm_ret = resid_capm @ resid_capm.T / T  # T x T\n",
    "\n",
    "# Factor mean and Covariance mu_f and sigma_f\n",
    "F = factors_capm.values\n",
    "mu_f = F.mean(axis=0).reshape(-1,1)  # k x 1\n",
    "F_centered = F - mu_f\n",
    "Sigma_f_tilde = (F_centered.T @ F_centered) / T # k x k\n",
    "\n",
    "# Prepare alphas and residual covariance\n",
    "alpha = np.asarray(alphas_capm).reshape(-1, 1)   # n x 1\n",
    "Sigma_e_tilde =  (1/T) * (resid_capm.T @ resid_capm)  # 25 x 25    \n",
    "\n",
    "# Compute GRS statistic\n",
    "s = 1.0 + (mu_f @ solve(Sigma_f_tilde, mu_f.T))[0, 0]\n",
    "num = (alpha.T @ solve(Sigma_e_tilde, alpha))[0, 0]\n",
    "\n",
    "df1 = n\n",
    "df2 = T - n - k \n",
    "GRS = ((T - n - k) / n) * (1.0 / s) * num\n",
    "pval = 1.0 - f.cdf(GRS, df1, df2)\n",
    "\n",
    "print(f\"GRS = {GRS:.4f},  p-value = {pval:.4g}, df=({df1},{df2})\")\n",
    "\n",
    "# Compute RMS alpha\n",
    "RMS_alpha = np.sqrt(np.mean(alphas_capm.flatten()**2))\n",
    "\n",
    "# Compute ARIV\n",
    "var_resid = np.var(resid_capm, axis=0, ddof=0)       # variance of residuals per portfolio\n",
    "var_total = np.var(R, axis=0, ddof=0)                # variance of returns per portfolio\n",
    "ARIV = np.mean(var_resid / var_total)\n",
    "\n",
    "# Build table\n",
    "results_df = pd.DataFrame({\n",
    "    \"Portfolio\": R.columns,\n",
    "    \"Alpha (%)\": alphas_capm.flatten() * 100,\n",
    "    \"SE Alpha (%)\": ses_capm.flatten() * 100\n",
    "})\n",
    "\n",
    "# Add overall statistics at bottom\n",
    "summary_df = pd.DataFrame({\n",
    "    \"Portfolio\": [\"RMS Alpha\", \"ARIV\", \"GRS\", \"p-value\"],\n",
    "    \"Alpha (%)\": [RMS_alpha, ARIV, GRS, pval],\n",
    "    \"SE Alpha (%)\": [\"\", \"\", \"\", \"\"]\n",
    "})\n",
    "\n",
    "# Final table\n",
    "final_table = pd.concat([results_df, summary_df], ignore_index=True)\n",
    "\n",
    "print(final_table)\n",
    "\n",
    "###################################################################################################\n",
    "### 3-Factor regressions ###\n",
    "###################################################################################################\n",
    "# Factors: Mkt-RF, SMB, RMW\n",
    "factors_3f = fac_q2_no_date[[\"Mkt-RF\", \"SMB\", \"RMW\"]]\n",
    "alphas_3f, ses_3f, resid_3f = [], [], []\n",
    "\n",
    "X_3f = sm.add_constant(factors_3f)\n",
    "for col in R.columns:\n",
    "    y = R[col].values\n",
    "    model = sm.OLS(y, X_3f).fit()\n",
    "    alphas_3f.append(model.params[0])  # intercept = alpha\n",
    "    ses_3f.append(model.bse[0])        # std error of alpha\n",
    "    resid_3f.append(model.resid)       # residuals\n",
    "\n",
    "# To arrays \n",
    "alphas_3f = np.array(alphas_3f).reshape(-1,1)   # n x 1 column vector\n",
    "ses_3f    = np.array(ses_3f).reshape(-1,1)\n",
    "resid_3f  = np.array(resid_3f).T                # T x n\n",
    "\n",
    "# Factor mean and Covariance mu_f and sigma_f\n",
    "F3 = factors_3f.values\n",
    "mu_f3 = F3.mean(axis=0).reshape(-1,1)                # k x 1\n",
    "F3_centered = F3 - mu_f3.T\n",
    "Sigma_f3_tilde = (F3_centered.T @ F3_centered) / T   # k x k\n",
    "\n",
    "# Residual covariance\n",
    "Sigma_e3_tilde = (1/T) * (resid_3f.T @ resid_3f)\n",
    "\n",
    "# Prepare GRS statistic components\n",
    "mu_f3_inv = np.linalg.inv(Sigma_f3_tilde) @ mu_f3\n",
    "s3 = 1.0 + float(mu_f3.T @ mu_f3_inv)\n",
    "alpha_inv = np.linalg.inv(Sigma_e3_tilde) @ alphas_3f\n",
    "num3 = float(alphas_3f.T @ alpha_inv)\n",
    "\n",
    "# GRS test statistic\n",
    "df1, df2 = n, T - n - 3\n",
    "GRS_3f = ((T - n - 3) / n) * (num3 / s3)\n",
    "pval_3f = 1.0 - f.cdf(GRS_3f, df1, df2)\n",
    "\n",
    "print(f\"GRS (3-factor) = {GRS_3f:.4f},  p-value = {pval_3f:.4g}, df=({df1},{df2})\")\n",
    "\n",
    "###################################################################################################\n",
    "### Summary stats: RMS Alpha & ARIV ###\n",
    "###################################################################################################\n",
    "RMS_alpha_3f = np.sqrt(np.mean(alphas_3f.flatten()**2))\n",
    "\n",
    "var_resid_3f = np.var(resid_3f, axis=0, ddof=0)\n",
    "var_total_3f = np.var(R, axis=0, ddof=0)\n",
    "ARIV_3f = np.mean(var_resid_3f / var_total_3f)\n",
    "\n",
    "print(f\"RMS Alpha (3f): {RMS_alpha_3f:.6f}\")  # keep in decimals\n",
    "print(f\"ARIV (3f): {ARIV_3f:.6f}\")            # keep in decimals\n",
    "\n",
    "###################################################################################################\n",
    "# TABLE #\n",
    "###################################################################################################\n",
    "# Build table for 3-factor model\n",
    "results_df_3f = pd.DataFrame({\n",
    "    \"Portfolio\": R.columns,\n",
    "    \"Alpha\": alphas_3f.flatten(),        # decimals\n",
    "    \"SE Alpha\": ses_3f.flatten()         # decimals\n",
    "})\n",
    "\n",
    "# Add overall statistics at bottom\n",
    "summary_df_3f = pd.DataFrame({\n",
    "    \"Portfolio\": [\"RMS Alpha\", \"ARIV\", \"GRS\", \"p-value\"],\n",
    "    \"Alpha\": [RMS_alpha_3f, ARIV_3f, GRS_3f, pval_3f],\n",
    "    \"SE Alpha\": [\"\", \"\", \"\", \"\"]\n",
    "})\n",
    "\n",
    "# Final table\n",
    "final_table_3f = pd.concat([results_df_3f, summary_df_3f], ignore_index=True)\n",
    "print(final_table_3f)\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "### Sharpe Ratios ###\n",
    "###################################################################################################\n",
    "# CAPM: Market Sharpe ratio \n",
    "# Mkt-RF column is already excess return of market\n",
    "market_excess = fac_q2_no_date[\"Mkt-RF\"].values \n",
    "mu_m = np.mean(market_excess)                          # mean excess return\n",
    "sigma_m = np.std(market_excess, ddof=0)                # std dev of excess return\n",
    "Sharpe_market = mu_m / sigma_m\n",
    "\n",
    "print(f\"Sharpe ratio (Market, CAPM): {Sharpe_market:.4f}\")\n",
    "\n",
    "# 3-Factor Model: Efficient portfolio Sharpe ratio \n",
    "mu_f3 = F3.mean(axis=0).reshape(-1,1)                # k x 1 mean of factors\n",
    "Sigma_f3 = np.cov(F3, rowvar=False, ddof=0)          # k x k covariance matrix of factors\n",
    "Sharpe_3f = np.sqrt(float(mu_f3.T @ np.linalg.inv(Sigma_f3) @ mu_f3))\n",
    "\n",
    "# CAPM efficient Sharpe (includes alphas) \n",
    "Sharpe_capm_sq = float(mu_f.T @ np.linalg.inv(Sigma_f_tilde) @ mu_f) + \\\n",
    "                 float(alphas_capm.T @ np.linalg.inv(Sigma_e_tilde) @ alphas_capm)\n",
    "Sharpe_capm = np.sqrt(Sharpe_capm_sq)\n",
    "print(f\"CAPM Sharpe ratio including alphas: {Sharpe_capm:.4f}\")\n",
    "\n",
    "# 3-Factor efficient Sharpe (includes alphas)\n",
    "Sharpe_3f_sq = float(mu_f3.T @ np.linalg.inv(Sigma_f3_tilde) @ mu_f3) + \\\n",
    "               float(alphas_3f.T @ np.linalg.inv(Sigma_e3_tilde) @ alphas_3f)\n",
    "Sharpe_3f_full = np.sqrt(Sharpe_3f_sq)\n",
    "print(f\" 3-factor Sharpe ratio including alphas: {Sharpe_3f_full:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09980109",
   "metadata": {},
   "source": [
    "# Q3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2cf7b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "### DATA CLEAN ###\n",
    "###################################################################################################\n",
    "excess_portfolio_returns_q3['Date'] = pd.to_datetime(excess_portfolio_returns_q3['Date'])\n",
    "\n",
    "date = excess_portfolio_returns_q3['Date']\n",
    "ret_df = excess_portfolio_returns_q3.drop(columns=['Date'])\n",
    "labels = ret_df.columns.tolist()\n",
    "ret = ret_df.to_numpy(dtype=float)\n",
    "\n",
    "###################################################################################################\n",
    "### SET GAMMA AND FACTOR LIST ###\n",
    "###################################################################################################\n",
    "gamma_list = [-1, 0, 20]   # -1 and 0 = PCA, 20 = RP-PCA\n",
    "num_factors_list = [1, 3]  # single factor and three factors\n",
    "\n",
    "###################################################################################################\n",
    "### RUN PCA FOR DIFFERENT GAMMA AND K ###\n",
    "###################################################################################################\n",
    "results = {}\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    for k in num_factors_list:\n",
    "        PCeigval, PCeigvec, PCrelative_eigval = pca(ret, gamma=gamma)\n",
    "\n",
    "        results[(gamma, k)] = {\n",
    "            \"eigvals\": PCeigval[:k],\n",
    "            \"eigvecs\": PCeigvec[:, :k],\n",
    "            \"rel_explained\": PCrelative_eigval[:k]\n",
    "        }\n",
    "        \n",
    "        print(f\"Gamma = {gamma}, k = {k}\")\n",
    "        print(\"Eigenvalues:\", PCeigval[:k])\n",
    "        print(\"Relative explained variance:\", PCrelative_eigval[:k])\n",
    "        print(\"-\" * 50)\n",
    "\n",
    "##########################################################################\n",
    "### RUN FACTOR REGRESSIONS AND COLLECT RESULTS ###\n",
    "##########################################################################\n",
    "summary_rows = []  # model-level summary\n",
    "alpha_tables = []  # per-portfolio alpha/SE tables\n",
    "\n",
    "for (gamma, k), res in results.items():\n",
    "    eigvecs = res[\"eigvecs\"]\n",
    "    factors = ret @ eigvecs\n",
    "    res[\"factors\"] = factors\n",
    "\n",
    "    alphas, alphas_se, betas, r2s, resid_vars, total_vars = [], [], [], [], [], []\n",
    "\n",
    "    for i in range(ret.shape[1]):  # loop portfolios\n",
    "        y = ret[:, i]\n",
    "        X = sm.add_constant(factors)\n",
    "        model = sm.OLS(y, X).fit()\n",
    "\n",
    "        alphas.append(model.params[0])\n",
    "        alphas_se.append(model.bse[0])\n",
    "        betas.append(model.params[1:])\n",
    "        r2s.append(model.rsquared)\n",
    "        resid_vars.append(np.var(model.resid, ddof=1))\n",
    "        total_vars.append(np.var(y, ddof=1))\n",
    "\n",
    "    # Save arrays\n",
    "    res[\"alphas\"] = np.array(alphas)\n",
    "    res[\"alphas_se\"] = np.array(alphas_se)\n",
    "    res[\"betas\"] = np.vstack(betas)\n",
    "    res[\"r2\"] = np.array(r2s)\n",
    "\n",
    "    # Model-level summary\n",
    "    rmse_alpha = np.sqrt(np.mean(res[\"alphas\"]**2))\n",
    "    ariv = np.mean(np.array(resid_vars) / np.array(total_vars))\n",
    "    res[\"alpha_rms\"] = rmse_alpha\n",
    "    res[\"ariv\"] = ariv\n",
    "\n",
    "    summary_rows.append({\n",
    "        \"Gamma\": gamma,\n",
    "        \"Model\": \"PCA\" if gamma == -1 else \"RP-PCA\",\n",
    "        \"Factors\": k,\n",
    "        \"RMSE alpha\": rmse_alpha,\n",
    "        \"ARIV\": ariv\n",
    "    })\n",
    "\n",
    "    # Portfolio-level alpha ± SE\n",
    "    model_name = f\"{'PCA' if gamma == -1 else 'RP-PCA'} (gamma={gamma}, k={k})\"\n",
    "    df_model = pd.DataFrame({\n",
    "        \"Portfolio\": labels,\n",
    "        model_name: [f\"{a:.4f} ({se:.4f})\" for a, se in zip(res[\"alphas\"], res[\"alphas_se\"])]\n",
    "    })\n",
    "    alpha_tables.append(df_model)\n",
    "\n",
    "##########################################################################\n",
    "### BUILD SUMMARY TABLES ###\n",
    "##########################################################################\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "print(\"\\n=== Model-level Summary ===\")\n",
    "print(summary_df)\n",
    "\n",
    "# Merge all alpha tables\n",
    "alpha_table = alpha_tables[0]\n",
    "for df_model in alpha_tables[1:]:\n",
    "    alpha_table = alpha_table.merge(df_model, on=\"Portfolio\")\n",
    "\n",
    "print(\"\\n=== Portfolio-level Alphas ± SE ===\")\n",
    "print(alpha_table)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3d74e27",
   "metadata": {},
   "source": [
    "# Q4) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6808d8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "## OOS: Loop over all (γ, k) combinations and evaluate \n",
    "###################################################################################################\n",
    "window = 240\n",
    "gamma_list = [-1, 0, 20]\n",
    "k_list = [1, 3]\n",
    "\n",
    "oos_summary = []\n",
    "\n",
    "for gamma in gamma_list:\n",
    "    for k in k_list:\n",
    "        print(f\"Running OOS for gamma={gamma}, k={k} ...\")\n",
    "        errors, preds, r_star = rolling_window_oos(ret, window=window, gamma=gamma, k=k)\n",
    "        rms_alpha, ariv, sharpe = evaluate_oos(errors, preds, r_star)\n",
    "        oos_summary.append({\n",
    "            \"Gamma\": gamma,\n",
    "            \"Model\": \"PCA\" if gamma==-1 else \"RP-PCA\",\n",
    "            \"Factors\": k,\n",
    "            \"OOS RMSα\": rms_alpha,\n",
    "            \"OOS ARIV\": ariv,\n",
    "            \"OOS SR\": sharpe\n",
    "        })\n",
    "\n",
    "oos_results_df = pd.DataFrame(oos_summary)\n",
    "# display(oos_results_df.round(4))\n",
    "\n",
    "\n",
    "errors_capm, preds_capm, r_star_capm = rolling_window_oos_given_factors(ret, fac[[\"Mkt-RF\"]])\n",
    "rms_capm, ariv_capm, sharpe_capm = evaluate_oos(errors_capm, preds_capm, r_star_capm)\n",
    "\n",
    "errors_3f, preds_3f, r_star_3f = rolling_window_oos_given_factors(ret, fac[[\"Mkt-RF\",\"SMB\",\"RMW\"]])\n",
    "rms_3f, ariv_3f, sharpe_3f = evaluate_oos(errors_3f, preds_3f, r_star_3f)\n",
    "\n",
    "oos_capm_3f = pd.DataFrame({\n",
    "    \"Model\": [\"CAPM (Mkt-RF)\", \"3-Factor (Mkt, SMB, RMW)\"],\n",
    "    \"OOS RMSα\": [rms_capm, rms_3f],\n",
    "    \"OOS ARIV\": [ariv_capm, ariv_3f],\n",
    "    \"OOS SR\": [sharpe_capm, sharpe_3f]\n",
    "}).round(4)\n",
    "\n",
    "# display(oos_capm_3f)\n",
    "\n",
    "# Combine PCA/RP-PCA results with CAPM and 3-Factor \n",
    "final_oos_table = pd.concat([\n",
    "    oos_results_df[[\"Model\", \"Gamma\", \"Factors\", \"OOS RMSα\", \"OOS ARIV\", \"OOS SR\"]],\n",
    "    pd.DataFrame({\n",
    "        \"Model\": [\"CAPM\", \"Fama–French 3-Factor\"],\n",
    "        \"Gamma\": [np.nan, np.nan],\n",
    "        \"Factors\": [1, 3],\n",
    "        \"OOS RMSα\": [rms_capm, rms_3f],\n",
    "        \"OOS ARIV\": [ariv_capm, ariv_3f],\n",
    "        \"OOS SR\": [sharpe_capm, sharpe_3f]\n",
    "    })\n",
    "], ignore_index=True)\n",
    "\n",
    "# Round \n",
    "final_oos_table = final_oos_table.round(4)\n",
    "display(final_oos_table)\n",
    "\n",
    "###################################################################################################\n",
    "## OOS: Alphas\n",
    "###################################################################################################\n",
    "# Fetch the porftolio names\n",
    "portfolio_names = Double_sorted_portfolio.columns[1:]\n",
    "\n",
    "alpha_table = pd.DataFrame(index=portfolio_names)\n",
    "\n",
    "# PCA / RP-PCA Models\n",
    "for gamma in gamma_list:\n",
    "    for k in k_list:\n",
    "        model_name = f\"{f'PCA (gamma = {gamma}' if gamma==-1 else f'RP-PCA(gamma={gamma}'}, k= {k})\"\n",
    "        errors, preds, r_star = rolling_window_oos(ret, window=240, gamma=gamma, k=k)\n",
    "        alpha_table[model_name] = evaluate_oos_alphas(errors, portfolio_names)[\"alpha_OOS\"]\n",
    "\n",
    "# CAPM \n",
    "errors_capm, _, _ = rolling_window_oos_given_factors(ret, fac[[\"Mkt-RF\"]])\n",
    "alpha_table[\"CAPM\"] = evaluate_oos_alphas(errors_capm, portfolio_names)[\"alpha_OOS\"]\n",
    "\n",
    "# 3-Factor \n",
    "errors_3f, _, _ = rolling_window_oos_given_factors(ret, fac[[\"Mkt-RF\",\"SMB\",\"RMW\"]])\n",
    "alpha_table[\"3-Factor\"] = evaluate_oos_alphas(errors_3f, portfolio_names)[\"alpha_OOS\"]\n",
    "\n",
    "alpha_table = alpha_table.round(4)\n",
    "\n",
    "last_three_transposed = final_oos_table.iloc[:, -3:].T\n",
    "\n",
    "# Set the column names of the transposed part to match alpha_table columns\n",
    "last_three_transposed.columns = alpha_table.columns\n",
    "\n",
    "# Use original column names as row names\n",
    "last_three_transposed.index.name = None  # Optional: remove index name\n",
    "last_three_transposed.index = final_oos_table.columns[-3:]\n",
    "\n",
    "# Append to alpha_table\n",
    "merged_table = pd.concat([alpha_table, last_three_transposed])\n",
    "\n",
    "# Display the result\n",
    "display(merged_table)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ca3fb3c",
   "metadata": {},
   "source": [
    "# Q5) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ddc2b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################################################\n",
    "# Q5: Factr Zoo OOS\n",
    "###################################################################################################\n",
    "# Load and clean Jensen factors\n",
    "jkf = csv_data.copy()\n",
    "jkf.columns = jkf.columns.str.strip()\n",
    "\n",
    "# Ensure proper date parsing\n",
    "jkf[\"Date\"] = pd.to_datetime(jkf[\"date\"], errors=\"coerce\")\n",
    "jkf[\"YYYYMM\"] = jkf[\"Date\"].dt.strftime(\"%Y%m\").astype(float)\n",
    "\n",
    "# Filter\n",
    "jkf = jkf[(jkf[\"YYYYMM\"] >= float(start_yyyymm)) & (jkf[\"YYYYMM\"] <= float(end_yyyymm))].copy()\n",
    "\n",
    "# Keep only numeric factor columns\n",
    "jkf_factors = jkf.drop(columns=[\"date\", \"Date\", \"YYYYMM\"]).apply(pd.to_numeric, errors=\"coerce\")\n",
    "\n",
    "# 25 double-sorted portfolios\n",
    "ret_q5 = (\n",
    "    filtered_portfolio\n",
    "    .drop(columns=[\"Date\"])\n",
    "    .apply(pd.to_numeric, errors=\"coerce\") / 100.0   # Convert % to decimal\n",
    ")\n",
    "\n",
    "# Align the two datasets (ensure same number of months)\n",
    "min_T = min(len(ret_q5), len(jkf_factors))\n",
    "ret_q5 = ret_q5.iloc[-min_T:, :].to_numpy(dtype=float)\n",
    "factors153 = jkf_factors.iloc[-min_T:, :].to_numpy(dtype=float)\n",
    "dates_aligned = jkf[\"Date\"].iloc[-min_T:].reset_index(drop=True)\n",
    "\n",
    "\n",
    "###################################################################################################\n",
    "# Combine into a single matrix\n",
    "###################################################################################################\n",
    "combined_matrix = np.hstack([ret_q5, factors153])\n",
    "print(\"Combined matrix shape:\", combined_matrix.shape)\n",
    "\n",
    "###################################################################################################\n",
    "# PCA / RP-PCA eigenvalues and Scree Plot \n",
    "###################################################################################################\n",
    "\n",
    "gammas = [-1, 0, 20]\n",
    "eigvals_dict = {}\n",
    "threshold = 0.9   # Treshold\n",
    "\n",
    "plt.figure(figsize=(8,5))\n",
    "\n",
    "for gamma in gammas:\n",
    "    eigvals, eigvecs, rel_eigvals = pca(combined_matrix, gamma=gamma)\n",
    "    eigvals_dict[gamma] = eigvals\n",
    "\n",
    "    # Plot descending eigenvalues \n",
    "    plt.plot(\n",
    "        range(1, len(eigvals)+1),\n",
    "        eigvals / np.sum(eigvals),\n",
    "        marker=\"o\",\n",
    "        label=f\"γ = {gamma}\"\n",
    "    )\n",
    "\n",
    "plt.title(\"Scree Plot – PCA vs RP-PCA (Descending Eigenvalues)\")\n",
    "plt.xlabel(\"Factor Number (sorted descending)\")\n",
    "plt.ylabel(\"Proportion of Total Variance\")\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "for gamma in gammas:\n",
    "    k_star = choose_k(eigvals_dict[gamma], threshold=threshold)\n",
    "    print(f\"γ = {gamma}: suggested k = {k_star} (90% variance explained)\")\n",
    "\n",
    "###################################################################################################\n",
    "# Out-of-Sample Evaluation: PCA / RP-PCA vs Benchmarks\n",
    "###################################################################################################\n",
    "\n",
    "window = 240\n",
    "k_values = {gamma: choose_k(eigvals_dict[gamma], threshold=threshold) for gamma in gammas}\n",
    "\n",
    "results = []\n",
    "\n",
    "###################################################################################################\n",
    "# Rolling OOS for PCA / RP-PCA\n",
    "###################################################################################################\n",
    "\n",
    "for gamma_val in gammas:\n",
    "    for k_val in [1, 3, k_values[gamma_val]]:\n",
    "        print(f\"Running OOS for γ={gamma_val}, k={k_val}\")\n",
    "        errors, preds, rstar = rolling_window_oos(\n",
    "            combined_matrix, window=window, gamma=gamma_val, k=k_val\n",
    "        )\n",
    "        rms_alpha, ariv, sharpe = evaluate_oos(errors, preds, rstar)\n",
    "        results.append({\n",
    "            \"Model\": \"RP-PCA\" if gamma_val >= 0 else \"PCA\",\n",
    "            \"Gamma\": gamma_val,\n",
    "            \"k\": k_val,\n",
    "            \"RMS_alpha\": rms_alpha,\n",
    "            \"ARIV\": ariv,\n",
    "            \"Sharpe\": sharpe\n",
    "        })\n",
    "\n",
    "###################################################################################################\n",
    "# Benchmark Models (CAPM and FF3)\n",
    "###################################################################################################\n",
    "benchmarks = {\n",
    "    \"CAPM\": fac[[\"Mkt-RF\"]],\n",
    "    \"FF3\" : fac[[\"Mkt-RF\", \"SMB\", \"RMW\"]]\n",
    "}\n",
    "\n",
    "for name, f_df in benchmarks.items():\n",
    "    print(f\"Running OOS for benchmark: {name}\")\n",
    "    errors_b, preds_b, rstar_b = rolling_window_oos_given_factors(\n",
    "        ret_q5, f_df, window=window\n",
    "    )\n",
    "    rms_b, ariv_b, sharpe_b = evaluate_oos(errors_b, preds_b, rstar_b)\n",
    "    results.append({\n",
    "        \"Model\": name,\n",
    "        \"Gamma\": None,\n",
    "        \"k\": f_df.shape[1],\n",
    "        \"RMS_alpha\": rms_b,\n",
    "        \"ARIV\": ariv_b,\n",
    "        \"Sharpe\": sharpe_b\n",
    "    })\n",
    "\n",
    "###################################################################################################\n",
    "# Combine and Display Final Table\n",
    "###################################################################################################\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "results_df = results_df.sort_values(by=[\"Model\", \"Gamma\", \"k\"]).reset_index(drop=True)\n",
    "\n",
    "print(\"=== Final Q5 Out-of-Sample Results ===\")\n",
    "display(results_df)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
